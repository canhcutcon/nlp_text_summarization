# ğŸš¨ HÆ¯á»šNG DáºªN FIX Lá»–I TRAINING LOSS = 0

## ğŸ“Œ TÃŒNH HUá»NG HIá»†N Táº I

Báº¡n Ä‘ang gáº·p lá»—i:
```
Training Loss: 0.000000
Validation Loss: nan
ROUGE: 0.000000
Generated: <0x03>  â† Garbage output!
```

**ÄÃ¢y lÃ  lá»—i NGHIÃŠM TRá»ŒNG** - model hoÃ n toÃ n khÃ´ng há»c Ä‘Æ°á»£c gÃ¬.

---

## ğŸ” BÆ¯á»šC 1: CHáº¨N ÄOÃN (Báº®T BUá»˜C)

### Cháº¡y script cháº©n Ä‘oÃ¡n:

1. Upload file `diagnostic_script.py` vÃ o mÃ´i trÆ°á»ng cá»§a báº¡n
2. Äáº£m báº£o folder `data/` cÃ³ Ä‘áº§y Ä‘á»§ files CSV
3. Cháº¡y:
```bash
python diagnostic_script.py
```

### Script nÃ y sáº½ kiá»ƒm tra:
- âœ… Model cÃ³ load Ä‘Ãºng khÃ´ng?
- âœ… Data cÃ³ há»£p lá»‡ khÃ´ng?
- âœ… Tokenization cÃ³ Ä‘Ãºng khÃ´ng?
- âœ… Forward pass cÃ³ tÃ­nh Ä‘Æ°á»£c loss khÃ´ng?
- âœ… Labels cÃ³ bá»‹ toÃ n -100 khÃ´ng?
- âœ… Gradients cÃ³ Ä‘Æ°á»£c tÃ­nh khÃ´ng?

### Äá»c káº¿t quáº£:

Script sáº½ in ra **DIAGNOSIS** á»Ÿ cuá»‘i. TÃ¬m cÃ¡c dÃ²ng:
- âŒ MÃ u Ä‘á» = Lá»–I NGHIÃŠM TRá»ŒNG
- âš ï¸  MÃ u vÃ ng = Cáº¢NH BÃO
- âœ… MÃ u xanh = OK

**QUAN TRá»ŒNG:** Náº¿u cÃ³ Báº¤T Ká»² dÃ²ng âŒ nÃ o, Ä‘á»«ng tiáº¿p tá»¥c train!

---

## ğŸ”§ BÆ¯á»šC 2: FIX THEO CHáº¨N ÄOÃN

### Váº¥n Ä‘á» 1: "Training loss is 0"

**NguyÃªn nhÃ¢n cÃ³ thá»ƒ:**
1. All labels are -100 (padding)
2. Model weights frozen
3. Wrong loss computation

**Fix:**
- DÃ¹ng notebook `mt5_emergency_fix.ipynb`
- Notebook nÃ y cÃ³ check tá»«ng bÆ°á»›c
- Sáº½ Dá»ªNG NGAY náº¿u phÃ¡t hiá»‡n váº¥n Ä‘á»

### Váº¥n Ä‘á» 2: "Generated sentinel tokens" 

**Triá»‡u chá»©ng:** 
```
Generated: <extra_id_0> <extra_id_37>
```

**NguyÃªn nhÃ¢n:**
- Tokenizer khÃ´ng match model
- Model khÃ´ng Ä‘Æ°á»£c init Ä‘Ãºng

**Fix:**
```python
# Äáº£m báº£o load Ä‘Ãºng cÃ¡ch:
MODEL_NAME = "google/mt5-small"  # Viáº¿t TRÆ¯á»šC!
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)
```

### Váº¥n Ä‘á» 3: "All labels are -100"

**Triá»‡u chá»©ng:**
```
Valid labels: 0/128 (0.0%)
```

**NguyÃªn nhÃ¢n:**
- Data collator sai cáº¥u hÃ¬nh
- Preprocessing function sai

**Fix:**
```python
# Äáº£m báº£o dÃ¹ng text_target:
labels = tokenizer(
    text_target=examples["summary"],  # â† text_target!
    max_length=128,
    truncation=True,
    padding=False
)
```

### Váº¥n Ä‘á» 4: "Loss is NaN"

**NguyÃªn nhÃ¢n:**
- FP16 precision issues
- Learning rate quÃ¡ cao
- Gradient explosion

**Fix:**
```python
training_args = Seq2SeqTrainingArguments(
    fp16=False,  # â† Táº®T FP16!
    learning_rate=5e-5,  # KhÃ´ng quÃ¡ cao
    gradient_clip_norm=1.0,  # Clip gradients
)
```

### Váº¥n Ä‘á» 5: "No gradients computed"

**NguyÃªn nhÃ¢n:**
- Model trong eval mode
- Parameters bá»‹ freeze

**Fix:**
```python
# Explicitly unfreeze:
for param in model.parameters():
    param.requires_grad = True

# Ensure training mode:
model.train()
```

---

## ğŸš€ BÆ¯á»šC 3: Sá»¬ Dá»¤NG EMERGENCY FIX NOTEBOOK

File: `mt5_emergency_fix.ipynb`

### Äáº·c Ä‘iá»ƒm:
1. âœ… **TÃ­ch há»£p diagnostic** - check má»i thá»© trÆ°á»›c khi train
2. âœ… **FP16 disabled** - trÃ¡nh numerical issues
3. âœ… **Higher learning rate** - 1e-4 thay vÃ¬ 1e-5
4. âœ… **Explicit checks** - Dá»ªNG NGAY náº¿u cÃ³ váº¥n Ä‘á»
5. âœ… **Frequent logging** - log má»—i 10 steps

### CÃ¡ch dÃ¹ng:

1. Upload `mt5_emergency_fix.ipynb`
2. Cháº¡y tá»«ng cell theo thá»© tá»±
3. **Äá»ŒC Ká»¸ OUTPUT** cá»§a má»—i cell
4. Náº¿u tháº¥y âŒ â†’ Dá»ªNG vÃ  bÃ¡o lá»—i
5. Chá»‰ train khi tháº¥y "ALL CHECKS PASSED"

### Cell quan trá»ng nháº¥t:

**"FINAL CHECK Before Training"** - Cell nÃ y sáº½:
- Test forward pass vá»›i batch tháº­t
- Kiá»ƒm tra loss > 0
- Kiá»ƒm tra gradients
- **Dá»ªNG NGAY náº¿u loss = 0 hoáº·c NaN**

```
Expected output:
   Loss: 5.2341  â† PHáº¢I > 0!
   âœ… Loss is normal!
   âœ… Gradients OK
   âœ… ALL CHECKS PASSED - READY TO TRAIN
```

Náº¿u tháº¥y:
```
   Loss: 0.0000
   âŒ CRITICAL ERROR: Loss is 0!
   DO NOT START TRAINING!
```

â†’ **Dá»ªNG NGAY**, khÃ´ng train!

---

## ğŸ“Š BÆ¯á»šC 4: THEO DÃ•I TRAINING

### BÆ°á»›c Ä‘áº§u tiÃªn (step 0-10):

**QUAN TRá»ŒNG:** Loss á»Ÿ 10 bÆ°á»›c Ä‘áº§u lÃ  CHá»ˆ Sá» QUAN TRá»ŒNG NHáº¤T!

âœ… **Normal:**
```
Step 1: Loss 7.234
Step 2: Loss 6.891
Step 3: Loss 6.543
...
Step 10: Loss 5.123
```

âŒ **Abnormal:**
```
Step 1: Loss 0.000  â† Dá»ªNG NGAY!
```

hoáº·c

```
Step 1: Loss nan  â† Dá»ªNG NGAY!
```

### Sau 500 steps:

âœ… **Good:**
```
Step 500:
  Training Loss: 2.543
  Validation Loss: 2.891
  ROUGE-1: 0.2531
  ROUGE-2: 0.1234
```

âŒ **Bad:**
```
Step 500:
  Training Loss: 0.000000  â† Váº«n lá»—i!
  Validation Loss: nan
  ROUGE: 0.000000
```

Náº¿u váº«n tháº¥y 0.000000 sau 500 steps â†’ **Dá»ªN NGAY**, cÃ³ váº¥n Ä‘á» cÄƒn báº£n!

---

## ğŸ¯ Ká»² Vá»ŒNG SAU KHI FIX ÄÃšNG

### Epoch 1:
- Training loss: 5-8 â†’ 2-3
- Val loss: 3-4
- ROUGE-1: 25-35%
- Generated text: CÃ³ nghÄ©a nhÆ°ng chÆ°a tá»‘t

### Epoch 2:
- Training loss: 2-3 â†’ 1.5-2
- Val loss: 2.5-3
- ROUGE-1: 40-55%
- Generated text: Tá»‘t hÆ¡n

### Epoch 3:
- Training loss: 1.5-2
- Val loss: 2-2.5
- ROUGE-1: 50-70%
- ROUGE-2: 30-50%
- Generated text: Tá»‘t

---

## ğŸ” DEBUGGING CHECKLIST

TrÆ°á»›c khi train, check:
- [ ] `diagnostic_script.py` cháº¡y khÃ´ng cÃ³ lá»—i âŒ
- [ ] Test loss > 0 (thÆ°á»ng 2-8)
- [ ] Test generation khÃ´ng ra sentinel tokens
- [ ] Labels khÃ´ng pháº£i toÃ n -100
- [ ] Model parameters cÃ³ requires_grad=True

Trong khi train:
- [ ] Step 1 loss > 0
- [ ] Loss giáº£m dáº§n
- [ ] KhÃ´ng cÃ³ NaN
- [ ] ROUGE > 0 sau eval Ä‘áº§u

Náº¿u fail báº¥t ká»³ check nÃ o â†’ **Dá»ªNG VÃ€ DEBUG**

---

## ğŸ’¡ QUICK FIXES

### Fix 1: Restart má»i thá»©
```python
# Kill all processes
!pkill -9 python

# Clear GPU
torch.cuda.empty_cache()
gc.collect()

# Reload everything tá»« Ä‘áº§u
```

### Fix 2: Reduce complexity
```python
# Train vá»›i subset nhá» Ä‘á»ƒ test
small_train = tokenized_datasets["train"].select(range(100))
small_val = tokenized_datasets["validation"].select(range(20))
```

### Fix 3: Simplify settings
```python
training_args = Seq2SeqTrainingArguments(
    # Minimal settings
    output_dir="./test",
    num_train_epochs=1,
    per_device_train_batch_size=2,
    fp16=False,  # Disable
    gradient_checkpointing=False,  # Disable
)
```

---

## ğŸ“ Náº¾U VáºªN KHÃ”NG ÄÆ¯á»¢C

### Thu tháº­p thÃ´ng tin:

1. Cháº¡y `diagnostic_script.py`, copy toÃ n bá»™ output
2. Screenshot 10 bÆ°á»›c training Ä‘áº§u tiÃªn
3. Copy thÃ´ng tin:
   - GPU model
   - CUDA version: `torch.version.cuda`
   - PyTorch version: `torch.__version__`
   - Transformers version: `transformers.__version__`

### Thá»­ model khÃ¡c:

Náº¿u mT5 váº«n lá»—i, thá»­:
```python
# ViT5 - specifically for Vietnamese
MODEL_NAME = "VietAI/vit5-base"
```

hoáº·c

```python
# Smaller mT5
MODEL_NAME = "google/mt5-base"
```

---

## ğŸ“¦ FILES SUMMARY

1. **diagnostic_script.py** - Cháº¡y Äáº¦U TIÃŠN Ä‘á»ƒ tÃ¬m lá»—i
2. **mt5_emergency_fix.ipynb** - Notebook vá»›i táº¥t cáº£ fix vÃ  checks
3. **Lá»–I_VÃ€_GIáº¢I_PHÃP.md** - Chi tiáº¿t vá» tá»«ng lá»—i
4. **HÆ¯á»šNG_DáºªN_FIX.md** - File nÃ y

---

## ğŸ“ HIá»‚U Vá»€ LOSS = 0

**Táº¡i sao loss = 0 lÃ  nghiÃªm trá»ng?**

1. Loss = 0 nghÄ©a lÃ  model nghÄ© nÃ³ Ä‘Ã£ "perfect"
2. NhÆ°ng ROUGE = 0 chá»©ng tá» output lÃ  garbage
3. Äiá»u nÃ y chá»©ng tá»:
   - Loss khÃ´ng Ä‘Æ°á»£c tÃ­nh Ä‘Ãºng
   - Labels bá»‹ sai
   - Model khÃ´ng thá»±c sá»± train

**Normal loss should be:**
- Initial: 5-8
- After training: 1.5-2
- **NEVER 0!**

---

## âœ… SUCCESS CRITERIA

Báº¡n Ä‘Ã£ fix xong khi tháº¥y:

```
Step 1: Loss 6.234 âœ…
Step 50: Loss 4.567 âœ…
Step 100: Loss 3.456 âœ…
Step 500:
  Training Loss: 2.345 âœ…
  Validation Loss: 2.891 âœ…
  ROUGE-1: 0.2891 âœ… (NOT 0!)
  
[EVAL] Sample prediction: HÃ  Ná»™i cÃ´ng bá»‘ káº¿t quáº£... âœ… (Vietnamese!)
```

KHÃ”NG PHáº¢I:
```
Step 1: Loss 0.000 âŒ
Step 500: Loss 0.000, ROUGE 0.000 âŒ
[EVAL] Sample prediction: <0x03> âŒ
```

---

ChÃºc may máº¯n! ğŸ€
