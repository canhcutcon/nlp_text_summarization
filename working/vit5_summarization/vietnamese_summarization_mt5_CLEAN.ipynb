{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vietnamese Text Summarization - mT5-Small Fine-tuning\n",
        "\n",
        "‚úÖ **Model**: google/mt5-small (300M params)\n",
        "‚úÖ **Task**: Abstractive Summarization for Vietnamese\n",
        "‚úÖ **Strategy**: Properly structured seq2seq with optimized hyperparameters\n",
        "‚úÖ **Dataset**: Vietnamese documents with human-written summaries\n",
        "\n",
        "---\n",
        "\n",
        "## Key Improvements in This Version\n",
        "\n",
        "1. **Standardized Summarization Task Format**\n",
        "   - Proper prefix: \"t√≥m t·∫Øt: \" for all inputs\n",
        "   - Consistent max lengths (input: 512, output: 128)\n",
        "\n",
        "2. **Stable Training Configuration**\n",
        "   - Learning rate: 2e-4 (optimal for mT5)\n",
        "   - Batch size: 2 with gradient accumulation: 8 (effective batch: 16)\n",
        "   - FP16 enabled on CUDA GPUs\n",
        "   - Warmup steps: 500\n",
        "\n",
        "3. **Comprehensive Evaluation**\n",
        "   - ROUGE-1, ROUGE-2, ROUGE-L metrics\n",
        "   - Sample output inspection (metrics aren't everything!)\n",
        "\n",
        "4. **Optimized Inference**\n",
        "   - Beam search: 4-6 beams\n",
        "   - Length penalty: 1.0-1.5\n",
        "   - Repetition penalty: 1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd828ef4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers datasets accelerate sentencepiece evaluate rouge-score py-rouge torch --root-user-action=ignore\n",
        "\n",
        "print(\"‚úÖ All packages installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92089722",
      "metadata": {},
      "source": [
        "## 2. GPU/Device Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c96df87",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üéØ GPU/Device Setup\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Clear GPU cache if available\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"‚úÖ Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    USE_FP16 = True\n",
        "    USE_GRAD_CHECKPOINT = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"‚ö†Ô∏è  Using CPU (training will be very slow)\")\n",
        "    print(\"   üí° Consider using Google Colab with free GPU\")\n",
        "    USE_FP16 = False\n",
        "    USE_GRAD_CHECKPOINT = False\n",
        "\n",
        "print(f\"\\nüìä Configuration:\")\n",
        "print(f\"   Device: {device}\")\n",
        "print(f\"   FP16: {USE_FP16}\")\n",
        "print(f\"   Gradient Checkpointing: {USE_GRAD_CHECKPOINT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4f9588c",
      "metadata": {},
      "source": [
        "## 3. Load and Verify Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1fe9971",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# Load dataset\n",
        "print(\"üìä Loading Vietnamese Summarization Dataset...\")\n",
        "train_df = pd.read_csv(\"data/train.csv\")\n",
        "val_df = pd.read_csv(\"data/validation.csv\")\n",
        "test_df = pd.read_csv(\"data/test.csv\")\n",
        "\n",
        "print(f\"‚úì Train: {len(train_df):,} samples\")\n",
        "print(f\"‚úì Validation: {len(val_df):,} samples\")\n",
        "print(f\"‚úì Test: {len(test_df):,} samples\")\n",
        "\n",
        "# Analyze data statistics\n",
        "def analyze_lengths(df: pd.DataFrame, name: str):\n",
        "    doc_words = df['document'].apply(lambda x: len(x.split()))\n",
        "    sum_words = df['summary'].apply(lambda x: len(x.split()))\n",
        "    compression_ratio = (sum_words.mean() / doc_words.mean() * 100)\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Avg document: {doc_words.mean():.0f} words, Avg summary: {sum_words.mean():.0f} words\")\n",
        "    print(f\"  Compression ratio: {compression_ratio:.1f}%\")\n",
        "\n",
        "analyze_lengths(train_df, \"Train\")\n",
        "analyze_lengths(val_df, \"Validation\")\n",
        "analyze_lengths(test_df, \"Test\")\n",
        "\n",
        "# Convert to HuggingFace Dataset\n",
        "dataset = DatasetDict({\n",
        "    'train': Dataset.from_pandas(train_df[['document', 'summary']], preserve_index=False),\n",
        "    'validation': Dataset.from_pandas(val_df[['document', 'summary']], preserve_index=False),\n",
        "    'test': Dataset.from_pandas(test_df[['document', 'summary']], preserve_index=False)\n",
        "})\n",
        "\n",
        "print(f\"\\nüìù Sample:\")\n",
        "sample = dataset['train'][0]\n",
        "print(f\"Document: {sample['document'][:200]}...\")\n",
        "print(f\"Summary: {sample['summary'][:150]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "900c7ad6",
      "metadata": {},
      "source": [
        "## 4. Load mT5-Small Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a2a8fbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer\n",
        ")\n",
        "import evaluate\n",
        "\n",
        "# Load mT5-Small model and tokenizer\n",
        "MODEL_NAME = \"google/mt5-small\"\n",
        "\n",
        "print(f\"üì• Loading model: {MODEL_NAME}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "print(f\"‚úÖ Model loaded successfully!\")\n",
        "print(f\"   Parameters: {model.num_parameters():,}\")\n",
        "print(f\"   Vocab size: {tokenizer.vocab_size:,}\")\n",
        "\n",
        "# Move to device\n",
        "model = model.to(device)\n",
        "print(f\"   Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26a3fc79",
      "metadata": {},
      "source": [
        "## 5. Chu·∫©n Ho√° D·ªØ Li·ªáu (Standardize Data)\n",
        "\n",
        "‚ö†Ô∏è **R·∫§T QUAN TR·ªåNG**: Task prefix \"t√≥m t·∫Øt: \" ƒë·ªÉ model hi·ªÉu ƒë√¢y l√† task summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d391604e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    \"\"\"\n",
        "    Chu·∫©n ho√° d·ªØ li·ªáu cho b√†i to√°n t√≥m t·∫Øt:\n",
        "    - Th√™m prefix \"t√≥m t·∫Øt: \" v√†o ƒë·∫ßu document\n",
        "    - Tokenize input v·ªõi max_length=512\n",
        "    - Tokenize output (summary) v·ªõi max_length=128\n",
        "    \"\"\"\n",
        "    # Th√™m task prefix\n",
        "    inputs = [\"t√≥m t·∫Øt: \" + doc for doc in examples[\"document\"]]\n",
        "\n",
        "    # Tokenize inputs\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding=False  # Dynamic padding s·∫Ω ƒë∆∞·ª£c x·ª≠ l√Ω b·ªüi DataCollator\n",
        "    )\n",
        "\n",
        "    # Tokenize targets/labels\n",
        "    labels = tokenizer(\n",
        "        text_target=examples[\"summary\"],\n",
        "        max_length=128,\n",
        "        truncation=True,\n",
        "        padding=False\n",
        "    )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "print(\"üîÑ Tokenizing dataset...\")\n",
        "tokenized_datasets = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    desc=\"Tokenizing\"\n",
        ")\n",
        "\n",
        "# Verify tokenization\n",
        "sample = tokenized_datasets[\"train\"][0]\n",
        "print(f\"\\n‚úÖ Tokenization complete!\")\n",
        "print(f\"   Input length: {len(sample['input_ids'])} tokens\")\n",
        "print(f\"   Label length: {len(sample['labels'])} tokens\")\n",
        "print(f\"\\n   Sample input: {tokenizer.decode(sample['input_ids'][:100])}\")\n",
        "print(f\"   Sample label: {tokenizer.decode(sample['labels'][:50])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9b5b035",
      "metadata": {},
      "source": [
        "## 6. Define Metrics\n",
        "\n",
        "‚ö†Ô∏è **CH√ö √ù**: ROUGE cao ‚â† t√≥m t·∫Øt hay. Lu√¥n ƒë·ªçc sample output b·∫±ng m·∫Øt ng∆∞·ªùi!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6489edc5",
      "metadata": {},
      "outputs": [],
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Compute ROUGE scores v√† hi·ªÉn th·ªã sample predictions\n",
        "    ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng th·ª±c t·∫ø\n",
        "    \"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # N·∫øu predictions l√† logits, l·∫•y argmax\n",
        "    if len(predictions.shape) == 3:\n",
        "        predictions = np.argmax(predictions, axis=-1)\n",
        "\n",
        "    # Decode predictions\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in labels (padding tokens)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # üëÅÔ∏è LU√îN HI·ªÇN TH·ªä SAMPLE ƒë·ªÉ ki·ªÉm tra ch·∫•t l∆∞·ª£ng th·ª±c t·∫ø\n",
        "    if len(decoded_preds) > 0:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(\"üìù SAMPLE PREDICTION (ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng th·ª±c t·∫ø):\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Prediction: {decoded_preds[0][:200]}\")\n",
        "        print(f\"Reference:  {decoded_labels[0][:200]}\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Clean text\n",
        "    decoded_preds = [\"\\n\".join(pred.strip().split()) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(label.strip().split()) for label in decoded_labels]\n",
        "\n",
        "    # Compute ROUGE\n",
        "    result = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=False\n",
        "    )\n",
        "\n",
        "    # Return scores\n",
        "    return {\n",
        "        \"rouge1\": result[\"rouge1\"],\n",
        "        \"rouge2\": result[\"rouge2\"],\n",
        "        \"rougeL\": result[\"rougeL\"],\n",
        "        \"rougeLsum\": result[\"rougeLsum\"],\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Metrics defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b342682",
      "metadata": {},
      "source": [
        "## 7. Setup Training (Baseline Stable Configuration)\n",
        "\n",
        "**Learning rate cho mT5:**\n",
        "- 1e-4 ‚Üí ·ªïn ƒë·ªãnh\n",
        "- 2e-4 ‚Üí nhanh h∆°n (recommended)\n",
        "- >3e-4 ‚Üí d·ªÖ n·ªï loss üí£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28e9ea0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data collator for dynamic padding\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=-100\n",
        ")\n",
        "\n",
        "# Training arguments (baseline ·ªïn ƒë·ªãnh)\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./mt5_vi_sum\",\n",
        "\n",
        "    # Batch size strategy\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=8,  # Gi·∫£ l·∫≠p batch size 16\n",
        "\n",
        "    # Learning rate\n",
        "    learning_rate=2e-4,  # Optimal for mT5\n",
        "    warmup_steps=500,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    # Evaluation strategy\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=1000,\n",
        "\n",
        "    # Generation settings for evaluation\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=128,\n",
        "    generation_num_beams=4,\n",
        "\n",
        "    # Optimization\n",
        "    fp16=USE_FP16,  # Enable FP16 on CUDA\n",
        "    gradient_checkpointing=USE_GRAD_CHECKPOINT,\n",
        "\n",
        "    # Logging\n",
        "    logging_steps=100,\n",
        "    logging_first_step=True,\n",
        "    save_total_limit=2,\n",
        "\n",
        "    # Best model selection\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"rougeL\",  # ROUGE-L l√† quan tr·ªçng nh·∫•t\n",
        "    greater_is_better=True,\n",
        "\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Create Seq2Seq Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Trainer initialized!\")\n",
        "print(f\"\\nüìä Training Configuration:\")\n",
        "print(f\"   Device: {device}\")\n",
        "print(f\"   FP16: {USE_FP16}\")\n",
        "print(f\"   Per-device batch size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"   Gradient accumulation: {training_args.gradient_accumulation_steps}\")\n",
        "print(f\"   Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
        "print(f\"   Learning rate: {training_args.learning_rate}\")\n",
        "print(f\"   Warmup steps: {training_args.warmup_steps}\")\n",
        "print(f\"   Total epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"   Eval every: {training_args.eval_steps} steps\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56d2bad2",
      "metadata": {},
      "source": [
        "## 8. Train Model üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24c01268",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üöÄ Starting training...\")\n",
        "print(\"=\"*70)\n",
        "print(\"Expected training time:\")\n",
        "print(\"  ‚Ä¢ RTX 4070 SUPER (12GB): ~1-1.5 hours\")\n",
        "print(\"  ‚Ä¢ CPU: ~10-15 hours (not recommended)\")\n",
        "print(\"  ‚Ä¢ Google Colab T4: ~2-3 hours\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ Training complete!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìä Evaluating on test set...\")\n",
        "results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST SET RESULTS\")\n",
        "print(\"=\"*70)\n",
        "for key, value in results.items():\n",
        "    if 'rouge' in key:\n",
        "        print(f\"{key.upper()}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Optimized Inference Function\n",
        "\n",
        "**Beam Search Tips:**\n",
        "- num_beams: 4-6\n",
        "- length_penalty: 1.0-1.5\n",
        "- repetition_penalty: 1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_summary(text, max_length=150, min_length=40, num_beams=4,\n",
        "                     length_penalty=1.2, repetition_penalty=1.2):\n",
        "    \"\"\"\n",
        "    Generate summary with optimized parameters\n",
        "\n",
        "    Args:\n",
        "        text: Input document\n",
        "        max_length: Maximum summary length (default: 150)\n",
        "        min_length: Minimum summary length (default: 40)\n",
        "        num_beams: Beam search beams (4-6 recommended)\n",
        "        length_penalty: Length penalty (1.0-1.5 recommended)\n",
        "        repetition_penalty: Repetition penalty (1.2 recommended)\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(\n",
        "        \"t√≥m t·∫Øt: \" + text,\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        min_length=min_length,\n",
        "        num_beams=num_beams,\n",
        "        length_penalty=length_penalty,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=3,\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test with examples\n",
        "print(\"\\n=== INFERENCE EXAMPLES ===\")\n",
        "for i in range(3):\n",
        "    test_text = dataset['test'][i]['document']\n",
        "    ground_truth = dataset['test'][i]['summary']\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Example {i+1}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Original ({len(test_text)} chars):\")\n",
        "    print(test_text[:200], \"...\\n\")\n",
        "\n",
        "    print(\"Generated Summary:\")\n",
        "    generated = generate_summary(test_text)\n",
        "    print(generated)\n",
        "\n",
        "    print(\"\\nGround Truth:\")\n",
        "    print(ground_truth)\n",
        "    print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = \"./mt5-small-vietnamese-final\"\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"‚úÖ Model saved to: {output_dir}\")\n",
        "print(f\"\\nTo load later:\")\n",
        "print(f'tokenizer = AutoTokenizer.from_pretrained(\"{output_dir}\")')\n",
        "print(f'model = AutoModelForSeq2SeqLM.from_pretrained(\"{output_dir}\")')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Quick Test with Custom Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with your own text\n",
        "custom_text = \"\"\"\n",
        "Chi·ªÅu 26/1, UBND TP H√† N·ªôi t·ªï ch·ª©c h·ªçp b√°o c√¥ng b·ªë k·∫øt qu·∫£ th·ª±c hi·ªán\n",
        "nhi·ªám v·ª• ph√°t tri·ªÉn kinh t·∫ø - x√£ h·ªôi nƒÉm 2024. Theo ƒë√≥, t·ªïng s·∫£n ph·∫©m\n",
        "tr√™n ƒë·ªãa b√†n (GRDP) c·ªßa H√† N·ªôi nƒÉm 2024 ∆∞·ªõc tƒÉng 7,5% so v·ªõi nƒÉm 2023,\n",
        "cao h∆°n m·ª©c tƒÉng tr∆∞·ªüng chung c·ªßa c·∫£ n∆∞·ªõc (7,09%).\n",
        "\"\"\"\n",
        "\n",
        "print(\"Original text:\")\n",
        "print(custom_text)\n",
        "print(\"\\nGenerated summary:\")\n",
        "summary = generate_summary(custom_text.strip())\n",
        "print(summary)\n",
        "\n",
        "# Try different parameters\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Testing different beam search parameters:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "params = [\n",
        "    {\"num_beams\": 4, \"length_penalty\": 1.0},\n",
        "    {\"num_beams\": 6, \"length_penalty\": 1.2},\n",
        "    {\"num_beams\": 4, \"length_penalty\": 1.5},\n",
        "]\n",
        "\n",
        "for i, param in enumerate(params, 1):\n",
        "    print(f\"\\n[Config {i}] num_beams={param['num_beams']}, length_penalty={param['length_penalty']}\")\n",
        "    summary = generate_summary(custom_text.strip(), **param)\n",
        "    print(summary)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
