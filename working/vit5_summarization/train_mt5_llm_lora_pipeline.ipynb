{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vietnamese Text Summarization: mT5 + LLM (LoRA) Pipeline\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Input Document\n",
    "      ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Stage 1: ViT5  ‚îÇ  Fast summarization\n",
    "‚îÇ                 ‚îÇ  Extract key info\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚Üì\n",
    "   Initial Summary\n",
    "         ‚Üì\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Stage 2: LLM   ‚îÇ  Rewrite with:\n",
    "‚îÇ   + LoRA        ‚îÇ  - Better fluency\n",
    "‚îÇ                 ‚îÇ  - Natural Vietnamese\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚Üì\n",
    "   Final Summary\n",
    "```\n",
    "\n",
    "## Benefits\n",
    "\n",
    "- ‚úÖ **Stage 1 (ViT5)**: Fast, accurate extraction\n",
    "- ‚úÖ **Stage 2 (LLM + LoRA)**: Intelligent rewriting, better fluency\n",
    "- ‚úÖ **Memory Efficient**: 4-bit quantization, works on 8GB+ GPU\n",
    "- ‚úÖ **Fast Training**: LoRA trains <1% of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets peft bitsandbytes accelerate evaluate tqdm sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Stage 1: ViT5 Model\n",
    "    'stage1_model': 'VietAI/vit5-base',  # or your trained checkpoint path\n",
    "    'stage1_checkpoint': './vit5_vi_sum/checkpoint-best',  # Path to your trained Stage 1 model\n",
    "    \n",
    "    # Stage 2: Vietnamese LLM\n",
    "    'stage2_model': 'Qwen/Qwen2.5-7B-Instruct',  # Vietnamese LLM\n",
    "    \n",
    "    # Data paths\n",
    "    'train_data': 'data/train.csv',\n",
    "    'val_data': 'data/validation.csv',\n",
    "    'test_data': 'data/test.csv',\n",
    "    \n",
    "    # LoRA Training\n",
    "    'output_dir': './lora_rewriter',\n",
    "    'epochs': 3,\n",
    "    'batch_size': 4,  # Adjust based on your GPU (RTX 3090: 8, RTX 4070: 4, RTX 3060: 2)\n",
    "    'learning_rate': 2e-4,\n",
    "    \n",
    "    # Optional: Limit samples for quick testing\n",
    "    'max_train_samples': None,  # Set to 1000 for quick test\n",
    "    'max_val_samples': None,    # Set to 100 for quick test\n",
    "    'max_test_samples': 100,\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_df = pd.read_csv(CONFIG['train_data'])\n",
    "val_df = pd.read_csv(CONFIG['val_data'])\n",
    "test_df = pd.read_csv(CONFIG['test_data'])\n",
    "\n",
    "# Limit samples if specified\n",
    "if CONFIG['max_train_samples']:\n",
    "    train_df = train_df.head(CONFIG['max_train_samples'])\n",
    "if CONFIG['max_val_samples']:\n",
    "    val_df = val_df.head(CONFIG['max_val_samples'])\n",
    "if CONFIG['max_test_samples']:\n",
    "    test_df = test_df.head(CONFIG['max_test_samples'])\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Train: {len(train_df):,} samples\")\n",
    "print(f\"  Val: {len(val_df):,} samples\")\n",
    "print(f\"  Test: {len(test_df):,} samples\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample data:\")\n",
    "print(f\"Document: {train_df.iloc[0]['document'][:200]}...\")\n",
    "print(f\"Summary: {train_df.iloc[0]['summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stage 1: Generate mT5 Summaries\n",
    "\n",
    "Use your trained ViT5 model to generate initial summaries for all training documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mt5_summaries(documents, model_path, batch_size=8, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generate summaries using trained mT5/ViT5 model\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîÑ Generating {len(documents)} summaries...\")\n",
    "    \n",
    "    # Load model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    summaries = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(documents), batch_size), desc=\"Generating\"):\n",
    "            batch_docs = documents[i:i+batch_size]\n",
    "            \n",
    "            # Add prefix and tokenize\n",
    "            inputs = tokenizer(\n",
    "                [\"t√≥m t·∫Øt: \" + doc for doc in batch_docs],\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(device)\n",
    "            \n",
    "            # Generate\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_length=128,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=3\n",
    "            )\n",
    "            \n",
    "            # Decode\n",
    "            batch_summaries = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            summaries.extend(batch_summaries)\n",
    "    \n",
    "    # Clean up\n",
    "    del model\n",
    "    del tokenizer\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"‚úÖ Generated {len(summaries)} summaries\")\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mT5 summaries for all datasets\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Generating Stage 1 summaries...\")\n",
    "train_mt5_summaries = generate_mt5_summaries(\n",
    "    train_df['document'].tolist(),\n",
    "    CONFIG['stage1_checkpoint'],\n",
    "    batch_size=8,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "val_mt5_summaries = generate_mt5_summaries(\n",
    "    val_df['document'].tolist(),\n",
    "    CONFIG['stage1_checkpoint'],\n",
    "    batch_size=8,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "test_mt5_summaries = generate_mt5_summaries(\n",
    "    test_df['document'].tolist(),\n",
    "    CONFIG['stage1_checkpoint'],\n",
    "    batch_size=8,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Show samples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample Stage 1 Outputs:\")\n",
    "print(\"=\"*80)\n",
    "for i in range(3):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Document: {train_df.iloc[i]['document'][:200]}...\")\n",
    "    print(f\"Stage 1 (mT5): {train_mt5_summaries[i]}\")\n",
    "    print(f\"Human: {train_df.iloc[i]['summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Training Dataset for LoRA\n",
    "\n",
    "Create prompt-based training examples:\n",
    "- **Input**: Original document + mT5 summary\n",
    "- **Target**: Human-written summary (rewriting goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(original_doc, mt5_summary, target_summary=None):\n",
    "    \"\"\"\n",
    "    Create prompt for training/inference\n",
    "    \"\"\"\n",
    "    # Truncate document for context\n",
    "    doc_preview = original_doc[:500] + \"...\" if len(original_doc) > 500 else original_doc\n",
    "    \n",
    "    prompt = f\"\"\"B·∫°n l√† chuy√™n gia vi·∫øt l·∫°i vƒÉn b·∫£n ti·∫øng Vi·ªát. Nhi·ªám v·ª•: c·∫£i thi·ªán b·∫£n t√≥m t·∫Øt sau.\n",
    "\n",
    "Y√™u c·∫ßu:\n",
    "- Gi·ªØ nguy√™n th√¥ng tin v√† √Ω nghƒ©a\n",
    "- C·∫£i thi·ªán s·ª± t·ª± nhi√™n v√† m·∫°ch l·∫°c\n",
    "- S·ª≠ d·ª•ng t·ª´ ng·ªØ ph√π h·ª£p ti·∫øng Vi·ªát\n",
    "- Ng·∫Øn g·ªçn, s√∫c t√≠ch\n",
    "\n",
    "VƒÇN B·∫¢N G·ªêC:\n",
    "{doc_preview}\n",
    "\n",
    "T√ìM T·∫ÆT C·∫¶N VI·∫æT L·∫†I:\n",
    "{mt5_summary}\n",
    "\n",
    "T√ìM T·∫ÆT ƒê√É C·∫¢I THI·ªÜN:\n",
    "\"\"\"\n",
    "    if target_summary:\n",
    "        prompt += target_summary\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def create_training_dataset(documents, mt5_summaries, target_summaries):\n",
    "    \"\"\"\n",
    "    Create training dataset with prompt format\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    for doc, mt5_sum, target_sum in zip(documents, mt5_summaries, target_summaries):\n",
    "        prompt = create_prompt(doc, mt5_sum, target_sum)\n",
    "        examples.append({\"text\": prompt})\n",
    "    \n",
    "    return Dataset.from_list(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training datasets\n",
    "print(\"Creating training datasets...\")\n",
    "\n",
    "train_dataset = create_training_dataset(\n",
    "    train_df['document'].tolist(),\n",
    "    train_mt5_summaries,\n",
    "    train_df['summary'].tolist()\n",
    ")\n",
    "\n",
    "val_dataset = create_training_dataset(\n",
    "    val_df['document'].tolist(),\n",
    "    val_mt5_summaries,\n",
    "    val_df['summary'].tolist()\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset created:\")\n",
    "print(f\"  Train examples: {len(train_dataset)}\")\n",
    "print(f\"  Val examples: {len(val_dataset)}\")\n",
    "\n",
    "# Show sample prompt\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample Training Prompt:\")\n",
    "print(\"=\"*80)\n",
    "print(train_dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Vietnamese LLM with 4-bit Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading LLM: {CONFIG['stage2_model']}\")\n",
    "print(\"Using 4-bit quantization to save memory...\")\n",
    "\n",
    "# 4-bit quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CONFIG['stage2_model'],\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG['stage2_model'])\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply LoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying LoRA configuration...\")\n",
    "\n",
    "# Prepare model for training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # LoRA rank (higher = more capacity, slower)\n",
    "    lora_alpha=32,  # Scaling factor\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Which modules to apply LoRA\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "print(\"\\nüìä Trainable parameters:\")\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tokenize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokenizing datasets...\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"‚úÖ Tokenization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train LoRA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up training...\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=CONFIG['output_dir'],\n",
    "    num_train_epochs=CONFIG['epochs'],\n",
    "    per_device_train_batch_size=CONFIG['batch_size'],\n",
    "    per_device_eval_batch_size=CONFIG['batch_size'],\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    warmup_steps=100,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "print(f\"   Total steps: {len(tokenized_train) // CONFIG['batch_size'] // 4 * CONFIG['epochs']}\")\n",
    "print(f\"   Eval every: 200 steps\")\n",
    "print(f\"   Expected time: ~2-3 hours (depending on GPU)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "print(\"\\nüíæ Saving LoRA adapter...\")\n",
    "model.save_pretrained(CONFIG['output_dir'])\n",
    "tokenizer.save_pretrained(CONFIG['output_dir'])\n",
    "\n",
    "print(f\"‚úÖ Training complete!\")\n",
    "print(f\"   Saved to: {CONFIG['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluation: Compare Stage 1 vs Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rewritten_summaries(documents, mt5_summaries, lora_checkpoint, batch_size=4):\n",
    "    \"\"\"\n",
    "    Generate rewritten summaries using trained LoRA\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîÑ Rewriting {len(mt5_summaries)} summaries with LoRA...\")\n",
    "    \n",
    "    # Load model with LoRA\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "    \n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        CONFIG['stage2_model'],\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    model = PeftModel.from_pretrained(base_model, lora_checkpoint)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(lora_checkpoint)\n",
    "    \n",
    "    rewritten = []\n",
    "    \n",
    "    for i in tqdm(range(len(documents)), desc=\"Rewriting\"):\n",
    "        # Create prompt (without target)\n",
    "        prompt = create_prompt(documents[i], mt5_summaries[i], target_summary=None)\n",
    "        \n",
    "        # Generate\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=200,\n",
    "                temperature=0.3,\n",
    "                top_p=0.9,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # Decode\n",
    "        full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Extract rewritten part\n",
    "        if \"T√ìM T·∫ÆT ƒê√É C·∫¢I THI·ªÜN:\" in full_response:\n",
    "            rewritten_summary = full_response.split(\"T√ìM T·∫ÆT ƒê√É C·∫¢I THI·ªÜN:\")[-1].strip()\n",
    "        else:\n",
    "            rewritten_summary = full_response[len(prompt):].strip()\n",
    "        \n",
    "        rewritten.append(rewritten_summary)\n",
    "    \n",
    "    del model\n",
    "    del base_model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"‚úÖ Rewriting complete\")\n",
    "    return rewritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate rewritten summaries for test set\n",
    "test_rewritten_summaries = generate_rewritten_summaries(\n",
    "    test_df['document'].tolist(),\n",
    "    test_mt5_summaries,\n",
    "    CONFIG['output_dir']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROUGE scores\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä EVALUATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Stage 1 (mT5 only) vs Human\n",
    "mt5_results = rouge.compute(\n",
    "    predictions=test_mt5_summaries,\n",
    "    references=test_df['summary'].tolist()\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Stage 1 (mT5 only):\")\n",
    "print(f\"   ROUGE-1: {mt5_results['rouge1']:.4f}\")\n",
    "print(f\"   ROUGE-2: {mt5_results['rouge2']:.4f}\")\n",
    "print(f\"   ROUGE-L: {mt5_results['rougeL']:.4f}\")\n",
    "\n",
    "# Stage 2 (mT5 + LoRA rewrite) vs Human\n",
    "rewritten_results = rouge.compute(\n",
    "    predictions=test_rewritten_summaries,\n",
    "    references=test_df['summary'].tolist()\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Stage 2 (mT5 + LoRA rewrite):\")\n",
    "print(f\"   ROUGE-1: {rewritten_results['rouge1']:.4f} ({rewritten_results['rouge1'] - mt5_results['rouge1']:+.4f})\")\n",
    "print(f\"   ROUGE-2: {rewritten_results['rouge2']:.4f} ({rewritten_results['rouge2'] - mt5_results['rouge2']:+.4f})\")\n",
    "print(f\"   ROUGE-L: {rewritten_results['rougeL']:.4f} ({rewritten_results['rougeL'] - mt5_results['rougeL']:+.4f})\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement = (\n",
    "    (rewritten_results['rougeL'] - mt5_results['rougeL']) / mt5_results['rougeL'] * 100\n",
    ")\n",
    "print(f\"\\n‚ú® Overall improvement: {improvement:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sample Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample comparisons\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìù SAMPLE COMPARISONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in range(min(5, len(test_df))):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Example {i+1}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"\\nüìÑ Original ({len(test_df.iloc[i]['document'])} chars):\")\n",
    "    print(test_df.iloc[i]['document'][:300] + \"...\")\n",
    "    \n",
    "    print(f\"\\nüìù Stage 1 (mT5) - {len(test_mt5_summaries[i])} chars:\")\n",
    "    print(test_mt5_summaries[i])\n",
    "    \n",
    "    print(f\"\\n‚ú® Stage 2 (Rewritten) - {len(test_rewritten_summaries[i])} chars:\")\n",
    "    print(test_rewritten_summaries[i])\n",
    "    \n",
    "    print(f\"\\nüë§ Human Reference - {len(test_df.iloc[i]['summary'])} chars:\")\n",
    "    print(test_df.iloc[i]['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation results\n",
    "results_df = pd.DataFrame({\n",
    "    'document': test_df['document'].tolist(),\n",
    "    'human_summary': test_df['summary'].tolist(),\n",
    "    'stage1_mt5': test_mt5_summaries,\n",
    "    'stage2_rewritten': test_rewritten_summaries,\n",
    "})\n",
    "\n",
    "output_file = 'evaluation_results.csv'\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"\\nüíæ Results saved to: {output_file}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'stage1_rouge1': mt5_results['rouge1'],\n",
    "    'stage1_rouge2': mt5_results['rouge2'],\n",
    "    'stage1_rougeL': mt5_results['rougeL'],\n",
    "    'stage2_rouge1': rewritten_results['rouge1'],\n",
    "    'stage2_rouge2': rewritten_results['rouge2'],\n",
    "    'stage2_rougeL': rewritten_results['rougeL'],\n",
    "    'improvement_pct': improvement,\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('evaluation_metrics.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metrics, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"üíæ Metrics saved to: evaluation_metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Production Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Use the trained pipeline for new documents\n",
    "from mt5_llm_lora_pipeline import MT5_LLM_Summarizer\n",
    "\n",
    "# Initialize with trained models\n",
    "summarizer = MT5_LLM_Summarizer(\n",
    "    stage1_model=CONFIG['stage1_checkpoint'],  # Your trained ViT5\n",
    "    stage2_model=CONFIG['stage2_model'],       # Base LLM\n",
    "    lora_checkpoint=CONFIG['output_dir'],      # Trained LoRA\n",
    "    use_4bit=True\n",
    ")\n",
    "\n",
    "# Test document\n",
    "test_text = \"\"\"\n",
    "Chi·ªÅu 26/1, UBND TP H√† N·ªôi t·ªï ch·ª©c h·ªçp b√°o c√¥ng b·ªë k·∫øt qu·∫£ th·ª±c hi·ªán\n",
    "nhi·ªám v·ª• ph√°t tri·ªÉn kinh t·∫ø - x√£ h·ªôi nƒÉm 2024. Theo ƒë√≥, t·ªïng s·∫£n ph·∫©m\n",
    "tr√™n ƒë·ªãa b√†n (GRDP) c·ªßa H√† N·ªôi nƒÉm 2024 ∆∞·ªõc tƒÉng 7,5% so v·ªõi nƒÉm 2023,\n",
    "cao h∆°n m·ª©c tƒÉng tr∆∞·ªüng chung c·ªßa c·∫£ n∆∞·ªõc (7,09%). Trong ƒë√≥, khu v·ª±c\n",
    "n√¥ng nghi·ªáp tƒÉng 3,2%, c√¥ng nghi·ªáp - x√¢y d·ª±ng tƒÉng 7,8%, d·ªãch v·ª• tƒÉng 7,4%.\n",
    "Thu ng√¢n s√°ch nh√† n∆∞·ªõc tr√™n ƒë·ªãa b√†n ƒë·∫°t 478.000 t·ª∑ ƒë·ªìng, v∆∞·ª£t 10,9% d·ª± to√°n.\n",
    "\"\"\"\n",
    "\n",
    "# Generate summary\n",
    "result = summarizer.summarize(test_text, use_stage2=True, verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRODUCTION TEST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nStage 1: {result['stage1']}\")\n",
    "print(f\"\\nStage 2: {result['stage2']}\")\n",
    "print(f\"\\nFinal: {result['final']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Training Complete!\n",
    "\n",
    "### What you achieved:\n",
    "\n",
    "1. ‚úÖ Trained LoRA adapter for Vietnamese summary rewriting\n",
    "2. ‚úÖ Evaluated Stage 1 (mT5) vs Stage 2 (mT5 + LoRA)\n",
    "3. ‚úÖ Saved trained model and evaluation results\n",
    "\n",
    "### Expected Results:\n",
    "\n",
    "- **Stage 1 (mT5)**: Fast, accurate but may be choppy\n",
    "- **Stage 2 (LoRA)**: +5-10% ROUGE improvement, much better fluency\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Review sample comparisons above\n",
    "2. Check `evaluation_results.csv` for full results\n",
    "3. Use trained pipeline in production (see example above)\n",
    "4. Fine-tune prompts if needed\n",
    "5. Try different LLMs for Stage 2 (Vistral, Gemma-2-Vi, etc.)\n",
    "\n",
    "### Saved Files:\n",
    "\n",
    "- `./lora_rewriter/` - Trained LoRA weights\n",
    "- `evaluation_results.csv` - Full evaluation results\n",
    "- `evaluation_metrics.json` - ROUGE scores\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook created:** 2025-01-06  \n",
    "**Status:** ‚úÖ Ready to use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
